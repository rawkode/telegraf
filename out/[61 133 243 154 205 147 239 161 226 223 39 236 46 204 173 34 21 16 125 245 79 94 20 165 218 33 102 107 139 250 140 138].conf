[global_tags]
dc = "$dcid"

[agent]
  interval = "120s"
  round_interval = true
  metric_batch_size = 1000
  metric_buffer_limit = 10000
  collection_jitter = "0s"
  flush_interval = "10s"
  flush_jitter = "0s"
  precision = ""
  debug = false
  quiet = false
  logfile = ""

  ## Override default hostname, if empty use os.Hostname()
  hostname = "$hostname"
  ## If set to true, do no set the "host" tag in the telegraf agent.
  omit_hostname = false

[inputs.docker]
  endpoint = "unix:///var/run/docker.sock"
  #   ## Only collect metrics for these containers, collect all if empty
  container_names = []
  #   ## Timeout for docker list, info, and stats commands
  timeout = "5s"
  perdevice = true
  #   ## Whether to report for each container total blkio and network stats or not
  total = false
# Read metrics about cpu usage
[[inputs.cpu]]
  ## Whether to report per-cpu stats or not
  percpu = true
  ## Whether to report total system cpu stats or not
  totalcpu = true
  ## If true, collect raw CPU time metrics.
  collect_cpu_time = false

# Read metrics about disk usage by mount point
[[inputs.disk]]
  ## By default, telegraf gather stats for all mountpoints.
  ## Setting mountpoints will restrict the stats to the specified mountpoints.
  # mount_points = ["/"]

  ## Ignore some mountpoints by filesystem type. For example (dev)tmpfs (usually
  ## present on /run, /var/run, /dev/shm or /dev).
  ignore_fs = ["tmpfs", "devtmpfs"]

# Read metrics about disk IO by device
[[inputs.diskio]]
  ## By default, telegraf will gather stats for all devices including
  ## disk partitions.
  ## Setting devices will restrict the stats to the specified devices.
  # devices = ["sda", "sdb"]
  ## Uncomment the following line if you need disk serial numbers.
  # skip_serial_number = false

# Get kernel statistics from /proc/stat
[[inputs.kernel]]
  # no configuration

# Read metrics about memory usage
[[inputs.mem]]
  # no configuration

# Get the number of processes and group them by status
[[inputs.processes]]
  # no configuration

# Read metrics about swap memory usage
[[inputs.swap]]
  # no configuration

# Read metrics about system load & uptime
[[inputs.system]]
  # no configuration

## example **********
### # Read JMX metrics through Jolokia
#[[inputs.jolokia2_agent]]
#  urls = ["http://$hostname:8082/jolokia","http://$hostname:8083/jolokia","http://$hostname:8084/jolokia","http://$hostname:8085/jolokia","http://$hostname:8086/jolokia","http://$hostname:8087/jolokia","http://$hostname:8089/jolokia"]
#
#[[inputs.jolokia2_agent.metric]]
#  name  = "java_runtime"
#  mbean = "java.lang:type=Runtime"
#  paths = ["Uptime"]
#
#[[inputs.jolokia2_agent.metric]]
#  name  = "java_memory"
#  mbean = "java.lang:type=Memory"
#  paths = ["HeapMemoryUsage", "NonHeapMemoryUsage", "ObjectPendingFinalizationCount"]
#
#[[inputs.jolokia2_agent.metrics]]
#  name     = "java_garbage_collector"
#  mbean    = "java.lang:name=*,type=GarbageCollector"
#  paths    = ["CollectionTime", "CollectionCount", "LastGcInfo"]
#  tag_keys = ["name"]
#
#[[inputs.jolokia2_agent.metrics]]
#  name  = "java_threading"
#  mbean = "java.lang:type=Threading"
#  paths = ["TotalStartedThreadCount", "ThreadCount", "DaemonThreadCount", "PeakThreadCount"]
#
#[[inputs.jolokia2_agent.metrics]]
#  name  = "java_class_loading"
#  mbean = "java.lang:type=ClassLoading"
#  paths = ["LoadedClassCount", "UnloadedClassCount", "TotalLoadedClassCount"]
#
#[[inputs.jolokia2_agent.metrics]]
#  name     = "java_memory_pool"
#  mbean    = "java.lang:name=*,type=MemoryPool"
#  paths    = ["Usage", "PeakUsage", "CollectionUsage"]
#  tag_keys = ["name"]

# example **********
[[inputs.http_response]]
  address = "http://servername:30151"
  ## Set response_timeout (default 5 seconds)
  response_timeout = "30s"
  ## HTTP Request Method
  method = "GET"

[[inputs.logparser]]
      ## Log files to parse.
      ## These accept standard unix glob matching rules, but with the addition of
      ## ** as a "super asterisk". ie:
      ##   /var/log/**.log     -> recursively find all .log files in /var/log
      ##   /var/log/*/*.log    -> find all .log files with a parent dir in /var/log
      ##   /var/log/apache.log -> only tail the apache log file
 files = ["/etc/docker/logs/*.log"]

      ## Read files that currently exist from the beginning. Files that are created
      ## while telegraf is running (and that match the "files" globs) will always
      ## be read from the beginning.
 from_beginning = false

      ## Method used to watch for file updates.  Can be either "inotify" or "poll".
      # watch_method = "inotify"

      ## Parse logstash-style "grok" patterns:
      ##   Telegraf built-in parsing patterns: https://goo.gl/dkay10
 [inputs.logparser.grok]
       ## This is a list of patterns to check the given log file(s) for.
       ## Note that adding patterns here increases processing time. The most
       ## efficient configuration is to have one pattern per logparser.
       ## Other common built-in patterns are:
       ##   %{COMMON_LOG_FORMAT}   (plain apache & nginx access logs)
       ##   %{COMBINED_LOG_FORMAT} (access logs + referrer & agent)
 patterns = ["%{GREEDYDATA:exception}"]

      ## Name of the outputted measurement name.
 measurement = "log_file_name"

          ## Full path(s) to custom pattern files.
 custom_pattern_files = []

          ## Custom patterns can also be defined here. Put one pattern per line.
 custom_patterns = '''
          '''

timezone = "Local"    
[outputs.kafka]
brokers = ["loalhost:9092"]
required_acks = 0
topic = "topic_name"
